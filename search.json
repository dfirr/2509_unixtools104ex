[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Unix Tools 104 – Workbook",
    "section": "",
    "text": "はじめに",
    "crumbs": [
      "はじめに"
    ]
  },
  {
    "objectID": "index.html#演習教材にようこそ",
    "href": "index.html#演習教材にようこそ",
    "title": "Unix Tools 104 – Workbook",
    "section": "演習教材にようこそ！",
    "text": "演習教材にようこそ！\nこの教材は、講習会の演習時間のために作成されています。",
    "crumbs": [
      "はじめに"
    ]
  },
  {
    "objectID": "index.html#作成環境について",
    "href": "index.html#作成環境について",
    "title": "Unix Tools 104 – Workbook",
    "section": "作成環境について",
    "text": "作成環境について\nこの文書や講義スライドは、Quartoと呼ばれるオープンソースの科学技術文書出版システムによって作成されています。\nQuartoでは、文章とコードと実行結果とを、1つの文書の中に収めることができます。文章はMarkdown形式に従うため、生成AIとの相性も抜群です。",
    "crumbs": [
      "はじめに"
    ]
  },
  {
    "objectID": "01-curl_jq.html",
    "href": "01-curl_jq.html",
    "title": "1  Web APIの処理（curl, jq）",
    "section": "",
    "text": "1.1 目的\nこの章の目的は、次の通りです。\n実際のWebサイトやWeb APIにアクセスして学習していきます。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Web APIの処理（curl, jq）</span>"
    ]
  },
  {
    "objectID": "01-curl_jq.html#目的",
    "href": "01-curl_jq.html#目的",
    "title": "1  Web APIの処理（curl, jq）",
    "section": "",
    "text": "HTTPのリクエストとレスポンスとを理解すること。\ncurlのオプションを身に着けること。\njqを使ってJSONファイルが加工できるようになること。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Web APIの処理（curl, jq）</span>"
    ]
  },
  {
    "objectID": "01-curl_jq.html#必要な準備",
    "href": "01-curl_jq.html#必要な準備",
    "title": "1  Web APIの処理（curl, jq）",
    "section": "1.2 必要な準備",
    "text": "1.2 必要な準備\nPCでWSL（Windows Subsystem for Linux）が使えるようになっている必要があります。\nスタートメニューで「terminal」とタイプし、表示されるターミナルアプリを選択して、Windowsターミナルを表示させてください。\n\n\n\n\n\nWindowsターミナルでは、デフォルトでWindows PowerShellが起動しています。「∨」マークをクリックし、表示されるメニューから「Ubuntu」を選択してください。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Web APIの処理（curl, jq）</span>"
    ]
  },
  {
    "objectID": "01-curl_jq.html#curl",
    "href": "01-curl_jq.html#curl",
    "title": "1  Web APIの処理（curl, jq）",
    "section": "1.3 curl",
    "text": "1.3 curl\n\n単純な閲覧\n阿部寛のホームページに、curlを使ってアクセスします。以下のコマンドを入力してください。\n\n\n\n\n\n\nノート\n\n\n\nコードブロックの右端にマウスカーソルを当てると📋アイコンが表示されます。クリックすると、コードがコピーできます。\n\n\ncurl -s 'http://abehiroshi.la.coocan.jp/'\ncurlのコマンドラインオプションは、以下の通りです。\n\n-s: メッセージを抑制する。\n\n&lt;html&gt;\n&lt;head&gt;\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=Shift_JIS\"&gt;\n&lt;meta name=\"GENERATOR\" content=\"JustSystems Homepage Builder Version 20.0.6.0 for Windows\"&gt;\n&lt;meta http-equiv=\"Content-Style-Type\" content=\"text/css\"&gt;\n&lt;title&gt;�������̃z�[���y�[�W&lt;/title&gt;\n&lt;/head&gt;\n&lt;frameset cols=18,82&gt;\n  &lt;frame src=\"menu.htm\" marginheight=\"0\" marginwidth=\"0\" scrolling=\"auto\" name=\"left\"&gt;\n  &lt;frame src=\"top.htm\" marginheight=\"0\" marginwidth=\"0\" scrolling=\"auto\" name=\"right\"&gt;\n  &lt;noframes&gt;\n  &lt;body&gt;&lt;/body&gt;\n  &lt;/noframes&gt;\n&lt;/frameset&gt;\n&lt;/html&gt;\n\n\n\n\n\n\n重要\n\n\n\nもし\nコマンド パイプライン位置 1 のコマンドレット Invoke-WebRequest\n次のパラメーターに値を指定してください:\nUri:\nのように表示されたら、WSLのUbuntuではなくPowerShellで実行しています。\n\n\nHTML形式で表示されていますが、&lt;title&gt;タグの内容が文字化けしています。これは、このホームページが今どき珍しくShift_JIS文字コードでエンコーディングされているのに対し、WSLのコンソールはUTF-8文字コードを前提としているためです。\nパイプ（|）を使って、Shift_JISをUTF-8に変換して出力します。\ncurl -s 'http://abehiroshi.la.coocan.jp/' | iconv -f sjis -t utf8\niconvのコマンドラインオプションは、以下の通りです。\n\n-f: 変換元の文字コード（from）\n-t: 変換先の文字コード（to）\n\n&lt;html&gt;\n&lt;head&gt;\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=Shift_JIS\"&gt;\n&lt;meta name=\"GENERATOR\" content=\"JustSystems Homepage Builder Version 20.0.6.0 for Windows\"&gt;\n&lt;meta http-equiv=\"Content-Style-Type\" content=\"text/css\"&gt;\n&lt;title&gt;阿部寛のホームページ&lt;/title&gt;\n&lt;/head&gt;\n&lt;frameset cols=18,82&gt;\n  &lt;frame src=\"menu.htm\" marginheight=\"0\" marginwidth=\"0\" scrolling=\"auto\" name=\"left\"&gt;\n  &lt;frame src=\"top.htm\" marginheight=\"0\" marginwidth=\"0\" scrolling=\"auto\" name=\"right\"&gt;\n  &lt;noframes&gt;\n  &lt;body&gt;&lt;/body&gt;\n  &lt;/noframes&gt;\n&lt;/frameset&gt;\n&lt;/html&gt;\n\n\n詳細表示\n-vオプションを追加することで、HTTPリクエストやレスポンスの内容、その他の付加情報が得られます。\ncurl -sv 'http://abehiroshi.la.coocan.jp/'\n\n\n\n\n\n\nノート\n\n\n\nオプションを-svのように一括して与えることも、-s -vのように分割して与えることもできます。\n\n\n* Host abehiroshi.la.coocan.jp:80 was resolved.\n* IPv6: 2001:258:8613:5000::101\n* IPv4: 222.158.205.72\n*   Trying 222.158.205.72:80...\n* Connected to abehiroshi.la.coocan.jp (222.158.205.72) port 80\n&gt; GET / HTTP/1.1\n&gt; Host: abehiroshi.la.coocan.jp\n&gt; User-Agent: curl/8.5.0\n&gt; Accept: */*\n&gt;\n&lt; HTTP/1.1 200 OK\n&lt; Date: Sat, 27 Sep 2025 09:02:50 GMT\n&lt; Content-Type: text/html\n&lt; Content-Length: 538\n&lt; Connection: keep-alive\n&lt; Last-Modified: Wed, 09 Jul 2025 05:12:05 GMT\n&lt; ETag: \"21a-639781e351da7\"\n&lt; Accept-Ranges: bytes\n&lt; Server: Apache\n&lt;\n&lt;html&gt;\n（以下略）\n&gt;ではじまる行がリクエスト（クライアント to サーバー）を、&lt;ではじまる行がレスポンス（サーバー to クライアント）を、*ではじまる行が付加情報を意味します。\nリクエストとレスポンスとの内容に注目し、以下の問いに答えてください。\n問題: HTTPのバージョンは何でしょうか？\n\n\n\n\n\n\n解答\n\n\n\n\n\n1.1です。\n\n\n\n問題: このHTTPリクエストは正常に応答されましたか？\n\n\n\n\n\n\n解答\n\n\n\n\n\nレスポンスが200 OKなので、正常に応答されています。\n\n\n\n問題: このHTML文書が最後に更新された日付は何ですか？\n\n\n\n\n\n\n解答\n\n\n\n\n\nWed, 09 Jul 2025 05:12:05 GMTなので、2025年7月9日です。\n\n\n\n\n\nステータスコード\n200以外のステータスコードを得てみます。「阿部寛のホームページ」には存在しないページに対してリクエストを出すと、404（Not Found）のエラーが返るはずです。\ncurl -sv 'http://abehiroshi.la.coocan.jp/test.html'\n* Host abehiroshi.la.coocan.jp:80 was resolved.\n* IPv6: 2001:258:8613:5000::101\n* IPv4: 222.158.205.72\n*   Trying 222.158.205.72:80...\n* Connected to abehiroshi.la.coocan.jp (222.158.205.72) port 80\n&gt; GET /test.html HTTP/1.1\n&gt; Host: abehiroshi.la.coocan.jp\n&gt; User-Agent: curl/8.5.0\n&gt; Accept: */*\n&gt;\n&lt; HTTP/1.1 404 Not Found\n&lt; Date: Sat, 27 Sep 2025 12:54:15 GMT\n&lt; Content-Type: text/html\n&lt; Content-Length: 3094\n&lt; Connection: keep-alive\n&lt;\n（以下略）\n\n\n\n\n\n\nノート\n\n\n\n-fオプションを付ると、400番台・500番台のステータスコードがサーバーから帰ってきた場合に、curlがエラー終了します。\nエラー終了した場合には、bashの$?が0以外の値になります。\ncurl -sf 'http://abehiroshi.la.coocan.jp/test.html'\necho $?\n22\n\n\nステータスコードは3桁の数字で、大分類は次の通りです。\n\n\n\nカテゴリ\n説明\n\n\n\n\n1xx: Informational\nリクエストを受け取り、処理を続行中\n\n\n2xx: Success\nリクエストが成功し、処理が完了した\n\n\n3xx: Redirection\nリクエストを完了するために別の場所へ移動が必要\n\n\n4xx: Client Error\nクライアント（利用者）のリクエストに問題がある\n\n\n5xx: Server Error\nサーバー側の問題でリクエストを処理できない\n\n\n\n1つ1つのコードの意味は、Mozillaのページで確認できます。Mozillaのページを参照し、以下の問いに答えてください。\n問題: 「Bad Gateway」のステータスコードは何番ですか？\n\n\n\n\n\n\n解答\n\n\n\n\n\n502です。\n\n\n\n問題: Webサイトを移転し、旧サイトに届いたリクエストは新サイトに転送したいと思います。 旧サイトにアクセスしたときには、どのステータスコードを返却すればよいですか？\n\n\n\n\n\n\n解答\n\n\n\n\n\n今回の移転が永続的であれば、301 Moved Permanentlyが適切です。一方で、メンテナンス中など一時的な移転であれば307 Temporary Redirectを返すのが適切です。\n\n\n\n問題: あるWeb APIでは、1秒間に10リクエストまでしか処理できない仕様です。 このWeb APIに対して1秒間に100リクエストを投げたとき、失敗する90リクエスト分に 付与されるステータスコードは何になるでしょうか？\n\n\n\n\n\n\n解答\n\n\n\n\n\nこのようなWeb API上の制限は、一般にRate Limitと呼ばれます。Rate Limitを示すステータスコードは、429 Too Many Requestsです。\n\n\n\n問題: ユーザーがサイトにログインを試みましたが、パスワードを間違えて認証に失敗しました。 返すべきステータスコードは何でしょうか。\n\n\n\n\n\n\n解答\n\n\n\n\n\n認証に失敗した場合には、401 Unauthorizedを返します。403 Forbiddenは、認証には成功している（もしくは認証機構がない）けれどもアクセス権がない場合に返すステータスコートです。\nただし、実際のWebアプリでは、認証に失敗したときに200 OKが返ってくることも多々あります。\n\n\n\n\n\n出力制御\n統計分析の入門用データセットに使用されるPalmer PenguinsのCSVファイルにアクセスします。\ncurl -s 'https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv'\nength_mm,body_mass_g,sex,year\nAdelie,Torgersen,39.1,18.7,181,3750,male,2007\nAdelie,Torgersen,39.5,17.4,186,3800,female,2007\nAdelie,Torgersen,40.3,18,195,3250,female,2007\nAdelie,Torgersen,NA,NA,NA,NA,NA,2007\n（以下略） \n-oオプションで、レスポンス内容をファイル出力できます。このときファイル名の指定が必要ですが、-Oオプションををつけるとサーバー上のファイル名で保存されます。\ncurl -s -O 'https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv'\nhead penguins.csv -n 10\n\nheadは、-nオプションで指定した行数だけ先頭から表示するコマンドです。\n\nspecies,island,bill_length_mm,bill_depth_mm,flipper_length_mm,body_mass_g,sex,year\nAdelie,Torgersen,39.1,18.7,181,3750,male,2007\nAdelie,Torgersen,39.5,17.4,186,3800,female,2007\nAdelie,Torgersen,40.3,18,195,3250,female,2007\nAdelie,Torgersen,NA,NA,NA,NA,NA,2007\nAdelie,Torgersen,36.7,19.3,193,3450,female,2007\nAdelie,Torgersen,39.3,20.6,190,3650,male,2007\nAdelie,Torgersen,38.9,17.8,181,3625,female,2007\nAdelie,Torgersen,39.2,19.6,195,4675,male,2007\nAdelie,Torgersen,34.1,18.1,193,3475,NA,2007\n問題: 先のCSVファイルを、「palmer.csv」という名前でダウンロード保存してください。\n\n\n\n\n\n\n解答\n\n\n\n\n\n-oオプションを使います。\ncurl -s -o palmer.csv 'https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv'\n\n\n\nダウンロード時に圧縮転送をしたければ、--compressedオプションをつけます。\n\n\n\n\n\n\nノート\n\n\n\n圧縮転送の効果を確認したければ、実際のダウンロード量を測定すればよいでしょう。-wオプションと%{size_download}という変数の組み合わせで実現できます。\ncurl -s -o /dev/null -w '%{size_download}\\n' 'https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv'\n\n/dev/nullは、Unixでのゴミ捨て場です。ファイルを何も保存しないことになります。\n\n15241\ncurl -s -o /dev/null -w '%{size_download}\\n' --compressed 'https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv'\n2976\nシンプルなテキストファイルなので、約1/5に圧縮されています。\n\n\n\n\nメソッド\nクライアントからサーバーにアクセスするとき、検索文字列やユーザー名など、パラメーターを送りたいときがあります。\nパラメーターを送る手法として、GETメソッドを使うケースと、POSTメソッドを使うケースとがあります。違いを以下に整理します。\n\n\n\n\n\n\n\n\n項目\nGET\nPOST\n\n\n\n\n主な用途\n情報を取得（読み取り）\n情報を送信・作成・更新\n\n\nパラメーターの埋め込み先\nURLのクエリ文字列（例：?key=value）\nリクエスト本文（Body）\n\n\nサイズ制限\nURL の長さに依存（ブラウザーで制限あり）\n通常は大きなデータを送信できる\n\n\nセキュリティ上の注意\nURLに露出するので機密情報を入れない\n暗号化しない限りは盗聴されうる\n\n\n\nhttpbin.orgは、HTTPクライアントのテスト用に作られたサービスです。その中に、こちらで送信したパラメーターをJSON形式で返却してくれる機能があります。GETを待ち受けるURLはhttps://httpbin.org/get、POSTを待ち受けるURLはhttps://httpbin.org/postです。\n以下のパラメーターの組を、GETとPOSTとで送ってみましょう。\n\n\n\nname\nage\n\n\n\n\nalice\n20\n\n\n\nGETメソッドでパラメーターを送信する際には、--url-queryオプションを使用します。https://httpbin.org/getに対して、上のパラメーターの組を送信する例を示します。\ncurl -s 'https://httpbin.org/get' --url-query 'name=alice' --url-query 'age=20' \n{\n  \"args\": {\n    \"age\": \"20\",\n    \"name\": \"alice\"\n  },\n（以下略）\nargsオブジェクトの中に、nameとageとが適切に格納されています。このように、--url-queryオプションを重ねて使うことで、複数のパラメーターが送信できます。\nPOSTメソッドでパラメーターを送信する際には、いくつかの流儀があります。\n古典的にはフォームエンコーディングが使用されます。これは埋め込むデータ自体は--url-queryと同じなのですが、埋め込む先がURLではなくリクエストボディ（本文）になっています。\ncurlでは、-dオプションを使ってパラメーターを送信すれば、デフォルトでフォームエンコーディングになります。\ncurl -s 'https://httpbin.org/post' -d 'name=alice' -d 'age=20'\n\nオプションの並び順は順不同です。-dオプションを最初にしてもかまいません。\n\n{\n  \"args\": {},\n  \"data\": \"\",\n  \"files\": {},\n  \"form\": {\n    \"age\": \"20\",\n    \"name\": \"alice\"\n  },\n  \"headers\": {\n    \"Accept\": \"*/*\",\n    \"Content-Length\": \"17\",\n    \"Content-Type\": \"application/x-www-form-urlencoded\",\n    \"Host\": \"httpbin.org\",\n    \"User-Agent\": \"curl/8.5.0\",\n    \"X-Amzn-Trace-Id\": \"Root=1-68d8dd7f-03fa73566f3703be53713741\"\n  },\n（以下略）\nWeb APIでは、フォームエンコーディングではなくJSON形式でデータを送信することが増えています。このときには、-dオプションではなく--jsonオプションを使用します。\ncurl -s 'https://httpbin.org/post' --json '{\"name\":\"alice\",\"age\":20}' \n{\n  \"args\": {},\n  \"data\": \"{\\\"name\\\":\\\"alice\\\",\\\"age\\\":20}\",\n  \"files\": {},\n  \"form\": {},\n  \"headers\": {\n    \"Accept\": \"application/json\",\n    \"Content-Length\": \"25\",\n    \"Content-Type\": \"application/json\",\n    \"Host\": \"httpbin.org\",\n    \"User-Agent\": \"curl/8.5.0\",\n    \"X-Amzn-Trace-Id\": \"Root=1-68d8df27-3286f7824e84acec473bbf66\"\n  },\n  \"json\": {\n    \"age\": 20,\n    \"name\": \"alice\"\n  },\n（以下略） \n問題: Yahoo! Japanの検索では、https://search.yahoo.co.jp/searchという URLに対し、p=&lt;検索文字列&gt;の形式でGETリクエストを投げて検索を実行します。 curlを使って、「阿部寛」で検索するコマンドを作ってください。\n\n\n\n\n\n\nヒント\n\n\n\n\n\n--url-queryオプションを使用します。\n\n\n\n\n\n\n\n\n\n解答\n\n\n\n\n\n次の通りです。\ncurl -s 'https://search.yahoo.co.jp/search' --url-query 'p=阿部寛'\n記号や日本語など、URLには混ぜてはいけない文字種があります。このときは文字列をURLエンコーディング変換する必要があるのですが、--url-queryオプションは、必要に応じて自動的に変換を行います。\np=阿部寛\nの部分は、URLエンコーディングされて\np=%e9%98%bf%e9%83%a8%e5%af%9b\nのようになります。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Web APIの処理（curl, jq）</span>"
    ]
  },
  {
    "objectID": "01-curl_jq.html#jq",
    "href": "01-curl_jq.html#jq",
    "title": "1  Web APIの処理（curl, jq）",
    "section": "1.4 jq",
    "text": "1.4 jq\nここまでもJSON形式を何度か見てきました。JSON（RFC 8259）は、Web APIにおけるデータ交換フォーマットの事実上の標準です。\nJSON形式は入れ子構造をもち、行指向ではないので、古典的なUnixツール（sed, awk, grepなど）で処理することは適切ではありません。かわりにjqを使うことで、awkに匹敵する処理が可能になります。\njqはUbuntu 24.0.3にプリインストールされていないので、aptコマンドでインストールしてください。\nsudo apt update\nsudo apt install -y jq\n\nパスワードを聞かれますので、入力してください。\n\njqがインストールされているかどうかは、whichコマンドで確かめられます。\nwhich jq\n/usr/bin/jq\nこのように、パスが戻ってきたらインストールされています。\n\nフィルター\nhttpbin.orgの機能の1つに、現在のグローバルIPアドレスを返却するものがあります。\ncurl -s 'https://httpbin.org/ip'\n{\n  \"origin\": \"61.25.0.94\"\n}\n結果はJSON形式で返されます。ここからIPアドレスだけを抽出するために、jqコマンドを使います。\ncurl -s 'https://httpbin.org/ip' | jq '.origin'\n\"61.25.0.94\"\n-rオプションを付けることで、二重引用符を取り除けます。\ncurl -s 'https://httpbin.org/ip' | jq -r '.origin'\n61.25.0.94\n\n\n条件抽出\nDummyJSONは、いろんな種類のダミーデータをJSON形式で与えてくれるサイトです。ここではユーザーデータを題材にし、jqによるJSON操作を学習しましょう。\nユーザーのダミーデータを得るには、次のようにします。（画面が流れるので、結果画面は省略します。）\ncurl -s 'https://dummyjson.com/users' \nこのままでは構造が不明なので、jqでパースし、先頭の10行だけを取得してみましょう。\ncurl -s 'https://dummyjson.com/users' | jq | head -n 10\n{\n  \"users\": [\n    {\n      \"id\": 1,\n      \"firstName\": \"Emily\",\n      \"lastName\": \"Johnson\",\n      \"maidenName\": \"Smith\",\n      \"age\": 28,\n      \"gender\": \"female\",\n      \"email\": \"emily.johnson@x.dummyjson.com\",\nこの結果を見ると、usersというオブジェクトの下に配列があり、その配列に実際のユーザーデータが存在するようです。\nユーザーは何人いるのでしょうか？　配列の要素数を調べる関数がjqには用意されています。\ncurl -s 'https://dummyjson.com/users' | jq '.users | length'\n30\n30人います。\n次に、ユーザーごとのフィールドの情報を把握するため、\"id\": 1のユーザー（Emily Johnson）のデータだけを取得します。\ncurl -s 'https://dummyjson.com/users' | jq '.users[] | select(.id == 1)'\n{\n  \"id\": 1,\n  \"firstName\": \"Emily\",\n  \"lastName\": \"Johnson\",\n  \"maidenName\": \"Smith\",\n  \"age\": 28,\n  \"gender\": \"female\",\n  \"email\": \"emily.johnson@x.dummyjson.com\",\n  \"phone\": \"+81 965-431-3024\",\n  \"username\": \"emilys\",\n  \"password\": \"emilyspass\",\n  \"birthDate\": \"1996-5-30\",\n  \"image\": \"https://dummyjson.com/icon/emilys/128\",\n  \"bloodGroup\": \"O-\",\n  \"height\": 193.24,\n  \"weight\": 63.16,\n  \"eyeColor\": \"Green\",\n  \"hair\": {\n    \"color\": \"Brown\",\n    \"type\": \"Curly\"\n  },\n  \"ip\": \"42.48.100.32\",\n  \"address\": {\n    \"address\": \"626 Main Street\",\n    \"city\": \"Phoenix\",\n    \"state\": \"Mississippi\",\n    \"stateCode\": \"MS\",\n    \"postalCode\": \"29112\",\n    \"coordinates\": {\n      \"lat\": -77.16213,\n      \"lng\": -92.084824\n    },\n    \"country\": \"United States\"\n  },\n  \"macAddress\": \"47:fa:41:18:ec:eb\",\n  \"university\": \"University of Wisconsin--Madison\",\n  \"bank\": {\n    \"cardExpire\": \"03/26\",\n    \"cardNumber\": \"9289760655481815\",\n    \"cardType\": \"Elo\",\n    \"currency\": \"CNY\",\n    \"iban\": \"YPUXISOBI7TTHPK2BR3HAIXL\"\n  },\n  \"company\": {\n    \"department\": \"Engineering\",\n    \"name\": \"Dooley, Kozey and Cronin\",\n    \"title\": \"Sales Manager\",\n    \"address\": {\n      \"address\": \"263 Tenth Street\",\n      \"city\": \"San Francisco\",\n      \"state\": \"Wisconsin\",\n      \"stateCode\": \"WI\",\n      \"postalCode\": \"37657\",\n      \"coordinates\": {\n        \"lat\": 71.814525,\n        \"lng\": -161.150263\n      },\n      \"country\": \"United States\"\n    }\n  },\n  \"ein\": \"977-175\",\n  \"ssn\": \"900-590-289\",\n  \"userAgent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.93 Safari/537.36\",\n  \"crypto\": {\n    \"coin\": \"Bitcoin\",\n    \"wallet\": \"0xb9fc2fe63b2a6c003f1c324c3bfa53259162181a\",\n    \"network\": \"Ethereum (ERC20)\"\n  },\n  \"role\": \"admin\"\n}\n紙面節約のために、firstName、lastName、ageの3つのフィールドだけを出力させます。\ncurl -s 'https://dummyjson.com/users' | \njq '.users[] | select(.id == 1) | {firstName, lastName, age}'\n{\n  \"firstName\": \"Emily\",\n  \"lastName\": \"Johnson\",\n  \"age\": 28\n}\n問題: 年齢が40歳以上の人のfirstName、lastName、ageを抽出してください。\n\n\n\n\n\n\nヒント\n\n\n\n\n\nselect関数の条件を変更します。\n\n\n\n\n\n\n\n\n\nヒント\n\n\n\n\n\n「以上」を示す記号は&gt;=です。\n\n\n\n\n\n\n\n\n\n解答\n\n\n\n\n\n40歳以上は4名存在します。\ncurl -s 'https://dummyjson.com/users' | \njq '.users[] | select(.age &gt;= 40) | {firstName, lastName, age}'\n{\n  \"firstName\": \"Sophia\",\n  \"lastName\": \"Brown\",\n  \"age\": 42\n}\n{\n  \"firstName\": \"James\",\n  \"lastName\": \"Davis\",\n  \"age\": 45\n}\n{\n  \"firstName\": \"Noah\",\n  \"lastName\": \"Hernandez\",\n  \"age\": 40\n}\n{\n  \"firstName\": \"Daniel\",\n  \"lastName\": \"Cook\",\n  \"age\": 41\n}\n\n\n\n\n\nフィールド生成\nfirstNameとlastNameという2つのフィールドから、nameという1つのフィールドを生成するには、次のようにします。\ncurl -s 'https://dummyjson.com/users' | \njq '.users[] | select(.id == 1) | {Name: (.firstName + \" \" + .lastName), age}'\n\n文字列の結合には+演算子を用います。\n(.firstName + \" \" + .lastName)によって、&lt;名&gt;&lt;空白&gt;&lt;姓&gt;という文字列が作られます。\nName:によって、文字列にキー名が付与されます。\n\n{\n  \"Name\": \"Emily Johnson\",\n  \"age\": 28\n}\n\n\nCSV加工\njqには、配列をCSVに変換するフィルター@csvが用意されています。\necho '[\"Emily\", 28]' | jq\n[\n  \"Emily\",\n  28\n]\necho '[\"Emily\", 28]' | jq -r @csv\n\"Emily\",28\n問題: 全員（30人）分の氏名と年齢とをCSV形式で出力してください。\n\n\n\n\n\n\n解答\n\n\n\n\n\n以下のようにします。\ncurl -s 'https://dummyjson.com/users' | \njq -r '.users[] | [(.firstName + \" \" + .lastName), .age] | @csv'\n\n[]によって配列を作る点がポイント。\n\n\"Emily Johnson\",28\n\"Michael Williams\",35\n\"Sophia Brown\",42\n\"James Davis\",45\n\"Emma Miller\",30\n\"Olivia Wilson\",22\n\"Alexander Jones\",38\n\"Ava Taylor\",27\n\"Ethan Martinez\",33\n\"Isabella Anderson\",31\n\"Liam Garcia\",29\n\"Mia Rodriguez\",24\n\"Noah Hernandez\",40\n\"Charlotte Lopez\",36\n\"William Gonzalez\",32\n\"Avery Perez\",25\n\"Evelyn Sanchez\",37\n\"Logan Torres\",31\n\"Abigail Rivera\",28\n\"Jackson Evans\",34\n\"Madison Collins\",26\n\"Elijah Stewart\",33\n\"Chloe Morales\",39\n\"Mateo Nguyen\",30\n\"Harper Kelly\",27\n\"Evelyn Gonzalez\",35\n\"Daniel Cook\",41\n\"Lily Lee\",29\n\"Henry Hill\",38\n\"Addison Wright\",32\n見出し行をつけることもできます。\ncurl -s 'https://dummyjson.com/users' | \njq -r '[\"Name\",\"Age\"], (.users[] | [(.firstName + \" \" + .lastName), .age]) | @csv'\n\"Name\",\"Age\"\n\"Emily Johnson\",28\n\"Michael Williams\",35\n\"Sophia Brown\",42\n（以下略）",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Web APIの処理（curl, jq）</span>"
    ]
  },
  {
    "objectID": "01-curl_jq.html#追加課題",
    "href": "01-curl_jq.html#追加課題",
    "title": "1  Web APIの処理（curl, jq）",
    "section": "1.5 追加課題",
    "text": "1.5 追加課題\nこの節で扱う内容の中には、授業で扱った水準を超えるものがあります。時間が許す場合や、より高度な内容に取り組みたいときに利用してください。Microsoft 365 Copilotなどの生成AIから手がかりを得てもよいかもしれません。\n\nヘッダーのみの表示\ncurl -sv 'http://abehiroshi.la.coocan.jp/'\nを使うとリクエストやレスポンスの詳細が得られますが、&gt;や&lt;などが行の先頭に付与されたり、リクエスト・レスポンスが一括で見えてしまいます。リクエストヘッダーやレスポンスヘッダー「だけ」を出力する方法を検討しましょう。\n問題: レスポンスヘッダー「だけ」を表示するには？\n\n\n\n\n\n\nヒント\n\n\n\n\n\n利用可能なオプションがないか、--help allを確認してみましょう。\n\n\n\n\n\n\n\n\n\nヒント\n\n\n\n\n\n -D, --dump-header &lt;filename&gt; Write the received headers to &lt;filename&gt;\nとあり、-D（または--dump-header）オプションが使えそうです。&lt;filename&gt;のかわりに標準出力に表示させたいときには、引数として-を渡します。\n\n\n\n\n\n\n\n\n\nヒント\n\n\n\n\n\nHTML本文を表示させたくないときには、出力先に/dev/nullを指定します。\n\n\n\n\n\n\n\n\n\n解答\n\n\n\n\n\n以下のようにすれば、レスポンスヘッダーだけが出力されます。（方法は1つとはかぎりません。同じ結果が得られれば大丈夫です。）\ncurl -s -D - -o /dev/null 'http://abehiroshi.la.coocan.jp/'\nHTTP/1.1 200 OK\nDate: Sat, 27 Sep 2025 10:19:52 GMT\nContent-Type: text/html\nContent-Length: 538\nConnection: keep-alive\nLast-Modified: Wed, 09 Jul 2025 05:12:05 GMT\nETag: \"21a-639781e351da7\"\nAccept-Ranges: bytes\nServer: Apache\n\n\n\n問題: リクエストヘッダー「だけ」を表示するには？\n\n\n\n\n\n\nヒント\n\n\n\n\n\nリクエストヘッダーを付加するためのcurlオプションは執筆時点では存在しないようです。目先を変え、-vオプションで出力してから必要な行だけを抽出することを考えてみましょう。\nこれらの加工には、古典的なUnixツールであるawk, cut, grep, sedなどが使えます。\n\n\n\n\n\n\n\n\n\nヒント\n\n\n\n\n\n実は、curlの-vオプションの出力先は標準出力ではなく標準エラー出力です。このため、パイプで渡すためには、2&gt;&1を加えて標準出力に乗せなければいけません。\n\n\n\n\n\n\n\n\n\n解答\n\n\n\n\n\n以下のようにすれば、リクエストヘッダーだけが出力されます。\ncurl -sv -o /dev/null 'http://abehiroshi.la.coocan.jp/' 2&gt;&1 | grep '^&gt;' | cut -c 3-\n\ncutコマンドの-cオプションは、指定したバイトを切り出します。 -c 3-と指定することで、3バイト目以降を切り出しています。 （すなわち&gt;を削除している。）\n\nGET / HTTP/1.1\nHost: abehiroshi.la.coocan.jp\nUser-Agent: curl/8.5.0\nAccept: */*\n\n\n\n\n\nUserAgentの偽装\nWebサイトの中には、アクセス元のデバイスによって挙動を変えるものがあります。以下のURLは、iPad版Google Chromeからアクセスしたときには閲覧でき、そうでなければ403 Forbiddenを返すことを意図しています。\nもしiPadをお持ちなら、実際にアクセスしてみてください。\ncurl -s 'http://www.10days.org/ipad/'\n&lt;!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\"&gt;\n&lt;html&gt;&lt;head&gt;\n&lt;title&gt;403 Forbidden&lt;/title&gt;\n&lt;/head&gt;&lt;body&gt;\n&lt;h1&gt;Forbidden&lt;/h1&gt;\n&lt;p&gt;You don't have permission to access this resource.&lt;/p&gt;\n&lt;/body&gt;&lt;/html&gt;\nこうした制限は、実装方式によっては容易に迂回できます。上のURLでは、リクエストヘッダーにあるUserAgentの値によって判定しています。\n問題: curlのオプションを駆使し、上記のURLを閲覧してください。\n\n\n\n\n\n\nヒント\n\n\n\n\n\n -A, --user-agent &lt;name&gt; Send User-Agent &lt;name&gt; to server\nとあり、-A（または--user-agent）オプションが使えそうです。\n\n\n\n\n\n\n\n\n\nヒント\n\n\n\n\n\niPad版Google ChromeのUserAgentは、Google検索するか生成AIから教えてもらえます。今回は、\nMozilla/5.0 (iPad; CPU OS 18_7 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) CriOS/141.0 Mobile/15E148 Safari/605.1\nとしてみましょう。\n\n\n\n\n\n\n\n\n\n解答\n\n\n\n\n\n以下のようにすれば閲覧できます。（実は-Aにはipadという文字列がありさえすればよいです。）\ncurl -s 'http://www.10days.org/ipad/' -A 'Mozilla/5.0 (iPad; CPU OS 18_7 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) CriOS/141.0 Mobile/15E148 Safari/605.1'\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n  &lt;meta charset=\"UTF-8\"&gt;\n  &lt;title&gt;Access Granted&lt;/title&gt;\n  &lt;style&gt;\n    body {\n      font-family: system-ui, -apple-system, sans-serif;\n      background: #f0f4f8;\n      color: #333;\n      text-align: center;\n      padding-top: 10%;\n    }\n    h1 {\n      font-size: 2.5rem;\n      color: #2a7ae2;\n      margin-bottom: 0.5em;\n    }\n    p {\n      font-size: 1.2rem;\n      color: #555;\n    }\n    .icon {\n      font-size: 4rem;\n      margin-bottom: 0.5em;\n    }\n  &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;div class=\"icon\"&gt;🍏&lt;/div&gt;\n  &lt;h1&gt;Access Granted&lt;/h1&gt;\n  &lt;p&gt;You have an &lt;strong&gt;iPad&lt;/strong&gt;!!&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\n\n\n\n\n各要素への処理\nJSON形式の各要素に対して何らかの処理を加えたいことがあります。たとえば、\ncurl -s 'https://dummyjson.com/users' | jq '.users[]'\nの中には年齢（age）フィールドがあります。この値をすべて変化させましょう。\n問題: jqを駆使し、ユーザー全員の年齢を2倍にしてください。\n\n\n\n\n\n\nヒント\n\n\n\n\n\n各要素に対して処理を行うフィルターには、mapやwalkがあります。mapは配列の1階層のみ、walkは任意の要素を再帰的にたどります。今回の用途ではmapで事足りるでしょう。\necho '[1,2,3,4]' | jq 'map(. * 2)'\n[\n  2,\n  4,\n  6,\n  8\n]\n\n\n\n\n\n\n\n\n\nヒント\n\n\n\n\n\n更新演算子|=を使うと、右辺の配列の値が上書きできます。\necho '{\"matrix\": [1,2,3,4]}' | jq '.matrix |= map(. * 2)'\n{\n  \"matrix\": [\n    2,\n    4,\n    6,\n    8\n  ]\n}\n\n\n\n\n\n\n\n\n\n解答\n\n\n\n\n\n以下のように、.usersの中で更新演算子を使うことで実現できます。\ncurl -s 'https://dummyjson.com/users' | jq '.users | map(.age |= . * 2)'\n\n\n\n\n\nグループ別集計\nJSON形式の特定の要素に着目して、集計をしたいことがあります。たとえば\ncurl -s 'https://dummyjson.com/users' | jq '.users[]'\nの中には血液型（bloodGroup）フィールドがあります。それぞれの血液型が何名いるのでしょうか？\n問題: jqを駆使し、血液型別の人数を求めてください。さらに 降順に並べてください。\n\n\n\n\n\n\nヒント\n\n\n\n\n\n配列から集計を行うためのフィルターに、reduceがあります。次のように使います。\nreduce &lt;入力配列&gt; as $var (初期値; 式)\n\n入力配列: 集計したい配列\n$var: ループ中の各要素を受け取る一時変数\n初期値: ループの初期値\n各要素に対して初期値を更新していく式\n\nたとえば\necho '[1,2,3,4,5]' | jq 'reduce .[] as $x (0; . + $x)'\n15\nreduceは[1,2,3,4,5]という配列の各要素を$xという一時変数に格納します。それらに対して加算していくので、結果は1 + 2 + 3 + 4 + 5になります。\n\n\n\n\n\n\n\n\n\nヒント\n\n\n\n\n\nキーごとに集計するためのjqの慣用句があります。次のコマンドは、nameフィールドごとにscoreの値を合計するためのものです。reduce以下に着目してください。\necho '[{\"name\":\"A\",\"score\":3},{\"name\":\"B\",\"score\":5},{\"name\":\"A\",\"score\":4}]' |\nreduce .[] as $p ({}; .[$p.name] |= ((. // 0) + $p.score))\n\n//は代替演算子で、.の値がnullやfalseであれば右辺（0）を返します。\n\n{\n  \"A\": 7,\n  \"B\": 5\n}\n処理をステップごとに見ていきましょう。\n\n初期値{}\n1人目$p={\"name\":\"A\",\"score\":3}\n\n.[\"A\"]は未定義 → 0\n0 + 3 → 3\n集計結果 → {\"A\":3}\n\n2人目$p={\"name\":\"B\",\"score\":5}\n\n.[\"B\"]は未定義 → 0\n0 + 5 → 5 -集計結果 → {\"A\":3,\"B\":5}\n\n3人目$p={\"name\":\"A\",\"score\":4}\n\n.[\"A\"]は3\n3 + 4 → 7\n集計結果 → {\"A\":7,\"B\":5}\n\n\n\n\n\n\n\n\n\n\n\nヒント\n\n\n\n\n\n並び替えにはsortを使いますが、sortにわたるデータはオブジェクトではなく配列でなければいけません。オブジェクトを配列にするためにはto_entries、配列をオブジェクトにするためにはfrom_entriesを使います。\n以下では、3名分のオブジェクトの値を降順でソートしています。\necho '{\"Alice\":7,\"Bob\":5,\"Charlie\":9}' |\njq '\n  to_entries |\n  sort_by(.value) |\n  reverse |\n  from_entries\n'\n{\n  \"Charlie\": 9,\n  \"Alice\": 7,\n  \"Bob\": 5\n}\n\n\n\n\n\n\nノート\n\n\n\njqのパイプラインを途中で止めて、どのような結果になるか観察してください。\n\n\n\n\n\n\n\n\n\n\n\n解答\n\n\n\n\n\n以下のように、reduceとto/from_entriesとを組み合わせて処理します。それにしても、AB-とO-が第1位・第2位を占めていることから、これが明らかにダミーデータであることが分かりますね。\ncurl -s 'https://dummyjson.com/users' |\njq '\n  reduce .users[] as $u ({}; .[$u.bloodGroup] |= (. // 0) + 1) |\n  to_entries |\n  sort_by(.value) |\n  reverse |\n  from_entries\n'\n{\n  \"AB-\": 7,\n  \"O-\": 6,\n  \"B+\": 5,\n  \"AB+\": 4,\n  \"O+\": 3,\n  \"B-\": 2,\n  \"A-\": 2,\n  \"A+\": 1\n}",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Web APIの処理（curl, jq）</span>"
    ]
  },
  {
    "objectID": "01-curl_jq.html#参考資料",
    "href": "01-curl_jq.html#参考資料",
    "title": "1  Web APIの処理（curl, jq）",
    "section": "1.6 参考資料",
    "text": "1.6 参考資料\n\nMozilla「開発者向けのウェブ技術」\nDaniel Stenberg「curl man page」\nKoichi Nakashima「新しいcurlコマンドの使い方 完全ガイド（2025年版）」\njqlang「jq 1.8 Manual」\n杜甫々「とほほのjq入門」",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Web APIの処理（curl, jq）</span>"
    ]
  }
]